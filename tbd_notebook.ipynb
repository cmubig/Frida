{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "from scripts import pix2pix\n",
    "\n",
    "\n",
    "def set_requires_grad(params, flag):\n",
    "    for p in params:\n",
    "        p.requires_grad = flag\n",
    "\n",
    "class RepeatChannel(nn.Module):\n",
    "    def __init__(self, repeat):\n",
    "        super(RepeatChannel, self).__init__()\n",
    "        self.repeat = repeat\n",
    "\n",
    "    def forward(self, img):\n",
    "        return img.repeat(1, self.repeat, 1, 1)\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, n_iter):\n",
    "        super(Downsample, self).__init__()\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def forward(self, img):\n",
    "        for _ in range(self.n_iter):\n",
    "            img = nn.functional.interpolate(img, scale_factor=0.5, mode='bicubic')\n",
    "        return img\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, n_iter):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def forward(self, img):\n",
    "        for _ in range(self.n_iter):\n",
    "            img = nn.functional.interpolate(img, scale_factor=2.0, mode='bicubic')\n",
    "        return img\n",
    "\n",
    "class OutputTransform(nn.Module):\n",
    "    def __init__(self, path, process='', diffaug_policy=''):\n",
    "        super(OutputTransform, self).__init__()\n",
    "        self.photosketch_path = path\n",
    "        self.augment = None\n",
    "\n",
    "        transforms = []\n",
    "        process = process.split(',')\n",
    "        for p in process:\n",
    "            if p.startswith('up'):\n",
    "                n_iter = int(p.replace('up', ''))\n",
    "                transforms.append(Upsample(n_iter))\n",
    "            elif p.startswith('down'):\n",
    "                n_iter = int(p.replace('down', ''))\n",
    "                transforms.append(Downsample(n_iter))\n",
    "            elif p == 'to3ch':\n",
    "                transforms.append(RepeatChannel(3))\n",
    "            elif p == 'toSketch':\n",
    "                sketch = self.setup_sketch(self.photosketch_path)\n",
    "                transforms.append(sketch)\n",
    "            else:\n",
    "                ValueError(\"Transforms contains unrecognizable key: %s\" % p)\n",
    "        self.transforms = nn.Sequential(*transforms)\n",
    "\n",
    "    def setup_sketch(self, photosketch_path):\n",
    "        sketch = pix2pix.ResnetGenerator(3, 1, n_blocks=9, use_dropout=False)\n",
    "\n",
    "        state_dict = torch.load(photosketch_path, map_location='cpu')\n",
    "        if hasattr(state_dict, '_metadata'):\n",
    "            del state_dict._metadata\n",
    "\n",
    "        sketch.load_state_dict(state_dict)\n",
    "        sketch.train()\n",
    "        set_requires_grad(sketch.parameters(), False)\n",
    "        return sketch\n",
    "\n",
    "    def forward(self, img, apply_aug=True):\n",
    "        img = self.transforms(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/Data1/vmisra/Frida/scripts/pretrained/photosketch.pth'\n",
    "t_real = 'toSketch'\n",
    "tf_real = OutputTransform(path, process=t_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = '/mnt/Data1/vmisra/Frida/scripts/frida.jpg'\n",
    "img = Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "width, height = img.size\n",
    "img_tensor = transform(img).float()\n",
    "img_tensor = img_tensor.reshape(1, 3, height, width)\n",
    "# img_tensor = torch.from_numpy(img)\n",
    "\n",
    "sketch = tf_real(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transform = transforms.Compose([\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "sketch_test = new_transform(sketch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('painting')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd3ee9297519a495c1c6cf7140d1fa55349d93fd91a721a9d6ba005084e151d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
